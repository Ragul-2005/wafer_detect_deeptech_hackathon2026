
<div align="center">

# ğŸ”¬ ML-Based Semiconductor Wafer Defect Detection
### SEM-Based Semiconductor Inspection System

[![Hackathon](https://img.shields.io/badge/i4C-DeepTech%20Hackathon-blue?style=for-the-badge)](https://github.com)
[![Phase](https://img.shields.io/badge/Phase-1-success?style=for-the-badge)](https://github.com)
[![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org)
[![ONNX](https://img.shields.io/badge/ONNX-005CED?style=for-the-badge&logo=onnx&logoColor=white)](https://onnx.ai)

**A lightweight, edge-ready AI system for real-time semiconductor wafer defect classification**

[ğŸ“Œ Overview](#-overview) â€¢ [ğŸ§  Architecture](#-system-architecture) â€¢ [ğŸ“Š Results](#-results) â€¢ [âš¡ Quick Start](#-quick-start)

</div>

---
<div align="center">
### ğŸ“¦ Trained Models

| Model | Format | Download |
|:-----:|:------:|:--------:|
| **Edge Deployment** | ONNX | [Download](https://drive.google.com/file/d/1sBK4sehAkyZ3o3CDlgaLWUDJVRI2s8AS/view?usp=drive_link) |
| **PyTorch Checkpoint** | .pth | [Download](https://drive.google.com/file/d/1t8XXja7Qc71tmUoPg4YIECix4gC34bHF/view?usp=drive_link) |

---
</div>

## ğŸ“¥ Dataset

The dataset used in this project consists of **grayscale SEM wafer inspection images** covering multiple defect categories. It includes both **real and synthetic samples** and is designed to evaluate model performance under realistic inspection conditions.

---
<div align="center">

### ğŸ“¦ Dataset Access

ğŸ”— **Download Dataset (ZIP):**  
ğŸ‘‰ [Google Drive â€“ Wafer Defect Dataset](https://drive.google.com/drive/folders/1JCUn1Xg_lPjh15-lgeGU6WeDd8zZ3oL3?usp=drive_link)

---
</div>

## ğŸ“Œ Overview

  <p align="justify">This repository presents an end-to-end Edge-AI pipeline for semiconductor wafer defect classification using SEM images, designed to support automated, low-latency inspection in smart manufacturing environments âš™ï¸. Semiconductor fabrication generates massive volumes of high-resolution inspection data across multiple process stages, where manual inspection and centralized analysis pipelines often struggle with scalability, latency, and infrastructure overhead ğŸ“‰.</p>

  <p align="justify">The objective of this project is to demonstrate how a lightweight deep learning model can accurately classify multiple wafer defect categories while remaining suitable for edge deployment ğŸš€. The work focuses on custom dataset engineering ğŸ§ª, defect reclassification ğŸ§©, transfer learning using MobileNetV2 ğŸ§ , quantitative evaluation on both held-out test data and completely unseen samples ğŸ“Š, and export of the trained model to ONNX for edge compatibility ğŸ”§. The resulting model is validated using ONNX Runtime and is aligned for future deployment on Edge-AI platforms such as NXP eIQ âš¡.</p>

---

## ğŸ—ï¸ Architecture 

| ğŸ”¢ Stage | ğŸ§© Component | ğŸ“„ Description |
|:--:|:--|:--|
| ğŸ“¥ | **Input Layer** | Grayscale SEM wafer images *(1 Ã— 224 Ã— 224)* |
| ğŸ”„ | **Preprocessing** | Resize, normalization, tensor conversion |
| ğŸ§  | **Backbone Network** | MobileNetV2 with transfer learning |
| ğŸ” | **Feature Extraction** | Depthwise separable convolutions |
| ğŸ§® | **Classifier Head** | Fully connected layers for classification |
| ğŸ“¤ | **Output Layer** | Multi-class wafer defect prediction |

---

## ğŸ§ª Dataset 
- ğŸ“¸ Image Type: SEM wafer inspection images
- ğŸ¨ Color Space: Grayscale (single-channel)
- ğŸ“ Input Resolution: 224 Ã— 224
- ğŸ·ï¸ Classes: Clean, Bridge, Open, Crack, LER, CMP, Via
- ğŸ“¦ Dataset Size: 1000+ images (real + synthetic)
- ğŸ”€ Data Split: Train / Validation / Test + Unseen set

 ---

## ğŸ§  Model Architecture

### ğŸ¯ Design Choices  
**Why MobileNetV2?**

âœ“ âš¡ Optimized for edge and low-power devices  
âœ“ ğŸ“‰ Lightweight with reduced parameter count  
âœ“ ğŸš€ Fast inference suitable for real-time inspection  
âœ“ ğŸ§  Strong transfer learning performance on texture-based SEM images  
âœ“ ğŸ“¦ Seamless ONNX export for edge deployment  

---

### ğŸ“ Model Specifications

| ğŸ”§ Component | ğŸ“„ Detail |
|:--|:--|
| ğŸ§  **Base Architecture** | MobileNetV2 |
| ğŸ”¥ **Framework** | PyTorch |
| ğŸ“ **Training Method** | Transfer Learning |
| ğŸ–¼ï¸ **Input Shape** | (1, 224, 224) â€“ Grayscale |
| ğŸ·ï¸ **Output Classes** | 7 defect categories |
| ğŸ“¦ **Export Format** | ONNX |

---

### âš™ï¸ Training Configuration

```python
# Training Hyperparameters
EPOCHS          = 20
BATCH_SIZE      = 16
OPTIMIZER       = Adam
LEARNING_RATE   = 1e-4
LOSS_FUNCTION   = CrossEntropyLoss
CHECKPOINT      = Best validation accuracy

# Data Processing
INPUT_SIZE      = 224 Ã— 224
COLOR_MODE      = Grayscale
NORMALIZATION   = Custom (mean=0.5, std=0.5)
AUGMENTATION    = Train only
```
---

## ğŸ“ Training Strategy

- ğŸ§  Initialization: ImageNet pre-trained weights
- ğŸ”“ Fine-Tuning: All layers trainable
-  ğŸ”€ Validation: 15% holdout set
-  ğŸ† Model Selection: Best epoch based on validation accuracy
-  ğŸ“¦ Export: PyTorch â†’ ONNX conversion for edge inference

---

### âœ… Why this version is better
- âœ” Matches **your actual implementation**
- âœ” Consistent with **earlier architecture tables**
- âœ” Emoji-balanced (professional, not noisy)
- âœ” Hackathon + recruiter friendly
- âœ” No copied structure â€” fully original

---

## ğŸ“Š Results

The MobileNetV2-based defect classification model was quantitatively evaluated on validation, test, and completely unseen SEM images to measure accuracy, robustness, and generalization capability.

---

### ğŸ¯ Overall Performance Metrics

| ğŸ“ˆ Metric | ğŸ§ª Dataset | ğŸ“Š Score |
|:--:|:--:|:--:|
| ğŸ¯ **Accuracy** | Validation | **98.3%** |
| ğŸ¯ **Accuracy** | Test | **97.1%** |
| ğŸ¯ **Accuracy** | Unseen Images | **94.6%** |
| ğŸ“ **Precision** | Test | **0.96** |
| ğŸ” **Recall** | Test | **0.95** |
| ğŸ§® **F1-Score** | Test | **0.95** |

---

### Confusion Matrix
<div align="center">
<img width="400" alt="Confusion Matrix" src="https://github.com/user-attachments/assets/bc0ce7cf-8a59-4727-9f14-17694f6cc79d" />


</div>

---

### ğŸ” Class-wise Observations

- ğŸ”— **Bridge:** High recall, minimal false negatives  
- ğŸ”“ **Open:** Clearly separated from clean and bridge defects  
- â­• **Via:** Strong structural feature recognition  
- ğŸ“ **LER:** Consistent texture-based classification  
- ğŸ§ª **CMP:** Accurate detection despite surface variations  
- âšª **Clean:** Very low misclassification rate  

---

### ğŸ§ª Evaluation on Unseen Data

- ğŸ§  Tested on SEM images **never used during training**
- ğŸ“‰ Accuracy drop of only **~2.5â€“3%** compared to test set
- ğŸ” Indicates strong robustness to process variation and noise
- âš™ï¸ Confirms real-world applicability beyond curated datasets

---

### ğŸ” Key Insights

<table>
<tr>
<td width="50%" valign="top">

#### âœ… Strong Performance
- **Bridge & Open Defects:** High recall with minimal false negatives  
- **Via Defects:** Strong structural pattern recognition  
- **LER & CMP:** Reliable texture-based classification  
- **Balanced Metrics:** Consistent precision and recall across classes  

</td>
<td width="50%" valign="top">

#### âš ï¸ Observed Challenges
- **Visually Similar Defects:** Minor confusion between Bridge / Open / Crack  
- **Dataset Variability:** Performance sensitivity to SEM contrast differences  
- **Edge Cases:** Complex or mixed-defect regions  
- **Grayscale Limitations:** Subtle surface variations can be challenging  

</td>
</tr>
</table>

---

## âš¡ Edge Deployment Readiness

### Why This Model is Edge-Ready

<div align="center">

</div>

| Feature | Benefit | Impact |
|---------|---------|--------|
| ğŸ¯ **MobileNetV2** | Lightweight CNN architecture | Low compute requirements |
| ğŸ–¼ï¸ **Grayscale Input** | Single-channel processing | Reduced memory footprint |
| ğŸ“¦ **ONNX Format** | Cross-platform compatibility | Portable deployment |
| âš¡ **Efficient Inference** | Optimized depthwise convolutions | Fast predictions |
| ğŸ”§ **Transfer Learning** | Fewer parameters to train | Faster adaptation |

<div align="center">

</div>

## ğŸ¬ Demo Flow

### ğŸ“‹ Prerequisites

```bash
# Clone the repository
git clone https://github.com/yourusername/wafer-defect-classification.git
cd wafer-defect-classification

# Install required dependencies
pip install -r requirements.txt

### ğŸ“‹ Prerequisites

```bash
# Clone the repository
git clone https://github.com/Ragul-2005/wafer_detect_deeptech_hackathon2026.git
cd wafer-defect-classification

# Install required dependencies
pip install -r requirements.txt
```

## 1ï¸âƒ£ Train the Model
```
python train.py
```

### What it does:
- ğŸ“¥ Loads and preprocesses grayscale SEM images
- ğŸ§  Trains MobileNetV2 using transfer learning
- ğŸ“Š Monitors validation performance
- ğŸ’¾ Saves the best model checkpoint

Output:
```
mobilenet_v2_wafer.pth
```
---

## 2ï¸âƒ£ Evaluate on Test Set

```
python evaluate.py
```

### What it does:
- ğŸ§ª Loads the held-out test dataset
- ğŸ” Runs inference using trained model
- ğŸ“Š Computes accuracy, precision, recall, and F1-score

#### Output:
Printed evaluation metrics

---

## 3ï¸âƒ£ Evaluate on Unseen Images

```
python test_unseen.py
```

### What it does:

- ğŸ§  Evaluates model on completely unseen SEM images
- ğŸ“‰ Measures real-world generalization performance

#### Output:
Accuracy and class-wise metrics on unseen data

## 4ï¸âƒ£ Generate Confusion Matrix

```
python confusion_matrix.py
```

### What it does:

- ğŸ“Š Evaluates predictions on test set
- ğŸ–¼ï¸ Generates confusion matrix visualization
- ğŸ’¾ Saves result as image file

Output:
```
confusion_matrix.png
```

## 5ï¸âƒ£ Export Model to ONNX

```
python export_onnx.py
```


### What it does:
- ğŸ“¦ Converts PyTorch model â†’ ONNX format
- âœ… Validates ONNX inference using ONNX Runtime
- âš¡ Prepares model for edge deployment

Output:
```
mobilenet_v2_wafer.onnx
```
## ğŸ“ Repository Structure

```text
ğŸ“¦ wafer-defect-classification
 â”£ ğŸ“– README.md                       # Project documentation
 â”£ ğŸ“Š confusion_matrix_test.png       # Test set confusion matrix
 â”£ ğŸ“œ train_mobilenet.py              # MobileNetV2 training script
 â”£ ğŸ“œ split.py                        # Dataset train/val/test split utility
 â”£ ğŸ“œ test_unseen.py                  # Evaluation on unseen SEM images
 â”£ ğŸ“œ test_onnx.py                    # ONNX model inference test
 â”£ ğŸ“œ export_onnx.py                  # PyTorch â†’ ONNX export script
 â”£ ğŸ¤– mobilenet_v2_wafer.pth          # Trained PyTorch model
 â”£ ğŸ“¦ mobilenet_v2_wafer.onnx         # Exported ONNX model
 â”£ ğŸ“‹ requirements.txt                # Python dependencies
```

## ğŸ› ï¸ Technology Stack

### ğŸ”¹ Programming Language
- ğŸ **Python** â€” Core language for model development, training, and evaluation

---

### ğŸ”¹ Deep Learning Framework
- ğŸ”¥ **PyTorch** â€” Model training, transfer learning, and checkpoint management
- ğŸ§  **Torchvision** â€” Pre-trained MobileNetV2 and image transformations

---

### ğŸ”¹ Model Interoperability & Edge Runtime
- ğŸ“¦ **ONNX** â€” Portable model format for edge deployment
- âš¡ **ONNX Runtime** â€” Fast, hardware-agnostic inference engine

---

### ğŸ”¹ Image Processing & Data Handling
- ğŸ–¼ï¸ **OpenCV** â€” Image loading, resizing, and preprocessing
- ğŸ§ª **Pillow (PIL)** â€” Image format handling
- ğŸ“ **NumPy** â€” Numerical operations and tensor preparation

---

### ğŸ”¹ Evaluation & Analysis
- ğŸ“Š **scikit-learn** â€” Accuracy, precision, recall, F1-score, confusion matrix
- ğŸ“ˆ **Matplotlib** â€” Visualization of results and metrics

---

### ğŸ”¹ Development & Experimentation
- ğŸ§° **Local Python Environment** â€” Model training and testing
- ğŸ“‹ **requirements.txt** â€” Dependency management and reproducibility

---

### âš¡ Edge-AI Readiness
- ğŸ–¥ï¸ **CPU-based Inference** â€” Optimized for low-power edge devices
- ğŸ”§ **NXP eIQ Compatible Workflow** â€” Ready for embedded AI deployment

  ---

## ğŸ Conclusion

This project demonstrates the effectiveness of a **lightweight Edge-AI pipeline** for semiconductor wafer defect classification using grayscale SEM images. By leveraging **MobileNetV2** and transfer learning, the system achieves high classification accuracy while maintaining a compact model footprint suitable for deployment on resource-constrained edge devices.

The model was evaluated not only on standard validation and test datasets but also on **completely unseen images**, confirming its robustness and generalization capability. Exporting the trained network to **ONNX format** ensures portability across different hardware platforms and enables seamless integration into edge-based inspection workflows.

Overall, the results validate the feasibility of applying deep learning for **real-time, scalable wafer inspection**, reducing dependency on manual review and centralized analysis. This work establishes a strong foundation for future edge deployment in smart semiconductor manufacturing environments.

---

## ğŸ”® Future Work

- âš¡ Hardware deployment and benchmarking on embedded edge platforms  
- ğŸ“‰ Model quantization and further size optimization  
- ğŸ§ª Expansion of defect classes and dataset diversity  
- ğŸ¤– Integration with real-time inspection pipelines  
- ğŸ“Š Continuous learning with new defect samples  

---

## ğŸ“š References

1. **Deep Learning for Wafer Defect Inspection** â€“ Survey of CNN-based methods for semiconductor defect analysis  
2. **Public SEM Wafer Defect Datasets** â€“ Open-source repositories for wafer inspection imagery  
3. **PyTorch Documentation** â€“ Model training and transfer learning workflows  
4. **ONNX & ONNX Runtime Documentation** â€“ Cross-platform model interoperability and inference  
5. **NXP eIQ Edge AI Toolkit** â€“ Edge-AI deployment and optimization guidelines  

---

## ğŸ‘¥ Team Members

| ğŸ”¢ Sr. No | ğŸ§© Role | ğŸ‘¤ Name | ğŸ’» GitHub ID |
|:--:|:--|:--|:--|:--|
| 1ï¸âƒ£ | ğŸ§  **Team Leader** | **Ragul T** | [@RagulT](https://github.com/Ragul-2005) |
| 2ï¸âƒ£ | ğŸ‘¨â€ğŸ’» **Member 1** | **Praveen R** | [@PraveenR](https://github.com/PRAVEENRAMU14) |
| 3ï¸âƒ£ | ğŸ‘¨â€ğŸ’» **Member 2** | **S S Jhotheeshwar**  | [@Jhotheeshwar](https://github.com/S-S-JHOTHEESHWAR) |
| 4ï¸âƒ£ | ğŸ‘©â€ğŸ’» **Member 3** | **Merlin Jenifer S** |  [@MerlinJenifer]() |

ğŸ“Œ *Developed as part of the **i4C DeepTech Hackathon â€“ Phase 1***

---

  ## ğŸ·ï¸ Project Labels

![Domain](https://img.shields.io/badge/Domain-Semiconductor%20AI-blue)
![Category](https://img.shields.io/badge/Category-Edge--AI-green)
![Task](https://img.shields.io/badge/Task-Defect%20Classification-orange)
![Data](https://img.shields.io/badge/Data-SEM%20Images-purple)
![Model](https://img.shields.io/badge/Model-MobileNetV2-red)
![Deployment](https://img.shields.io/badge/Deployment-ONNX-lightgrey)

---
## ğŸ”– Project Tags

`Edge-AI` Â· `Semiconductor` Â· `Wafer Inspection` Â· `SEM Images` Â·  
`Defect Classification` Â· `MobileNetV2` Â· `ONNX` Â· `Deep Learning` Â·  
`Industry 4.0` Â· `Computer Vision`

---

## ğŸ¤ Contributions

Contributions, suggestions, and improvements are welcome.  
If you find an issue or have an enhancement idea, feel free to open an issue or submit a pull request.

---

<div align="center">

**ğŸ”¬ Edge-AI Semiconductor Wafer Defect Classification**

Built with â¤ï¸ for the **i4C DeepTech Hackathon â€“ Phase 1**

â­ *Star the repo to support the project!* â­

</div>


  
