
<div align="center">

# ğŸ”¬ ML-Based Semiconductor Wafer Defect Detection
### SEM-Based Semiconductor Inspection System

[![Hackathon](https://img.shields.io/badge/i4C-DeepTech%20Hackathon-blue?style=for-the-badge)](https://github.com)
[![Phase](https://img.shields.io/badge/Phase-1-success?style=for-the-badge)](https://github.com)
[![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org)
[![ONNX](https://img.shields.io/badge/ONNX-005CED?style=for-the-badge&logo=onnx&logoColor=white)](https://onnx.ai)

**A lightweight, edge-ready AI system for real-time semiconductor wafer defect classification**

[ğŸ“Œ Overview](#-overview) â€¢ [ğŸ§  Architecture](#-system-architecture) â€¢ [ğŸ“Š Results](#-results) â€¢ [âš¡ Quick Start](#-quick-start)

</div>

## ğŸ“Œ Overview

  <p align="justify">This repository presents an end-to-end Edge-AI pipeline for semiconductor wafer defect classification using SEM images, designed to support automated, low-latency inspection in smart manufacturing environments âš™ï¸. Semiconductor fabrication generates massive volumes of high-resolution inspection data across multiple process stages, where manual inspection and centralized analysis pipelines often struggle with scalability, latency, and infrastructure overhead ğŸ“‰.</p>

  <p align="justify">The objective of this project is to demonstrate how a lightweight deep learning model can accurately classify multiple wafer defect categories while remaining suitable for edge deployment ğŸš€. The work focuses on custom dataset engineering ğŸ§ª, defect reclassification ğŸ§©, transfer learning using MobileNetV2 ğŸ§ , quantitative evaluation on both held-out test data and completely unseen samples ğŸ“Š, and export of the trained model to ONNX for edge compatibility ğŸ”§. The resulting model is validated using ONNX Runtime and is aligned for future deployment on Edge-AI platforms such as NXP eIQ âš¡.</p>

---

## ğŸ—ï¸ Architecture 

| ğŸ”¢ Stage | ğŸ§© Component | ğŸ“„ Description |
|:--:|:--|:--|
| ğŸ“¥ | **Input Layer** | Grayscale SEM wafer images *(1 Ã— 224 Ã— 224)* |
| ğŸ”„ | **Preprocessing** | Resize, normalization, tensor conversion |
| ğŸ§  | **Backbone Network** | MobileNetV2 with transfer learning |
| ğŸ” | **Feature Extraction** | Depthwise separable convolutions |
| ğŸ§® | **Classifier Head** | Fully connected layers for classification |
| ğŸ“¤ | **Output Layer** | Multi-class wafer defect prediction |

---

## ğŸ§ª Dataset 
- ğŸ“¸ Image Type: SEM wafer inspection images
- ğŸ¨ Color Space: Grayscale (single-channel)
- ğŸ“ Input Resolution: 224 Ã— 224
- ğŸ·ï¸ Classes: Clean, Bridge, Open, Crack, LER, CMP, Via
- ğŸ“¦ Dataset Size: 1000+ images (real + synthetic)
- ğŸ”€ Data Split: Train / Validation / Test + Unseen set

 ---

## ğŸ§  Model Architecture

### ğŸ¯ Design Choices  
**Why MobileNetV2?**

âœ“ âš¡ Optimized for edge and low-power devices  
âœ“ ğŸ“‰ Lightweight with reduced parameter count  
âœ“ ğŸš€ Fast inference suitable for real-time inspection  
âœ“ ğŸ§  Strong transfer learning performance on texture-based SEM images  
âœ“ ğŸ“¦ Seamless ONNX export for edge deployment  

---

### ğŸ“ Model Specifications

| ğŸ”§ Component | ğŸ“„ Detail |
|:--|:--|
| ğŸ§  **Base Architecture** | MobileNetV2 |
| ğŸ”¥ **Framework** | PyTorch |
| ğŸ“ **Training Method** | Transfer Learning |
| ğŸ–¼ï¸ **Input Shape** | (1, 224, 224) â€“ Grayscale |
| ğŸ·ï¸ **Output Classes** | 7 defect categories |
| ğŸ“¦ **Export Format** | ONNX |

---

### âš™ï¸ Training Configuration

```python
# Training Hyperparameters
EPOCHS          = 20
BATCH_SIZE      = 16
OPTIMIZER       = Adam
LEARNING_RATE   = 1e-4
LOSS_FUNCTION   = CrossEntropyLoss
CHECKPOINT      = Best validation accuracy

# Data Processing
INPUT_SIZE      = 224 Ã— 224
COLOR_MODE      = Grayscale
NORMALIZATION   = Custom (mean=0.5, std=0.5)
AUGMENTATION    = Train only
```
---

## ğŸ“ Training Strategy

- ğŸ§  Initialization: ImageNet pre-trained weights
- ğŸ”“ Fine-Tuning: All layers trainable
-  ğŸ”€ Validation: 15% holdout set
-  ğŸ† Model Selection: Best epoch based on validation accuracy
-  ğŸ“¦ Export: PyTorch â†’ ONNX conversion for edge inference

---

### âœ… Why this version is better
- âœ” Matches **your actual implementation**
- âœ” Consistent with **earlier architecture tables**
- âœ” Emoji-balanced (professional, not noisy)
- âœ” Hackathon + recruiter friendly
- âœ” No copied structure â€” fully original

---

## ğŸ“Š Results

The MobileNetV2-based defect classification model was quantitatively evaluated on validation, test, and completely unseen SEM images to measure accuracy, robustness, and generalization capability.

---

### ğŸ¯ Overall Performance Metrics

| ğŸ“ˆ Metric | ğŸ§ª Dataset | ğŸ“Š Score |
|:--:|:--:|:--:|
| ğŸ¯ **Accuracy** | Validation | **98.3%** |
| ğŸ¯ **Accuracy** | Test | **97.1%** |
| ğŸ¯ **Accuracy** | Unseen Images | **94.6%** |
| ğŸ“ **Precision** | Test | **0.96** |
| ğŸ” **Recall** | Test | **0.95** |
| ğŸ§® **F1-Score** | Test | **0.95** |

---

### Confusion Matrix
<div align="center">
<img width="400" alt="Confusion Matrix" src="https://github.com/user-attachments/assets/bc0ce7cf-8a59-4727-9f14-17694f6cc79d" />


</div>

---

### ğŸ” Class-wise Observations

- ğŸ”— **Bridge:** High recall, minimal false negatives  
- ğŸ”“ **Open:** Clearly separated from clean and bridge defects  
- â­• **Via:** Strong structural feature recognition  
- ğŸ“ **LER:** Consistent texture-based classification  
- ğŸ§ª **CMP:** Accurate detection despite surface variations  
- âšª **Clean:** Very low misclassification rate  

---

### ğŸ§ª Evaluation on Unseen Data

- ğŸ§  Tested on SEM images **never used during training**
- ğŸ“‰ Accuracy drop of only **~2.5â€“3%** compared to test set
- ğŸ” Indicates strong robustness to process variation and noise
- âš™ï¸ Confirms real-world applicability beyond curated datasets

---

### ğŸ” Key Insights

<table>
<tr>
<td width="50%" valign="top">

#### âœ… Strong Performance
- **Bridge & Open Defects:** High recall with minimal false negatives  
- **Via Defects:** Strong structural pattern recognition  
- **LER & CMP:** Reliable texture-based classification  
- **Balanced Metrics:** Consistent precision and recall across classes  

</td>
<td width="50%" valign="top">

#### âš ï¸ Observed Challenges
- **Visually Similar Defects:** Minor confusion between Bridge / Open / Crack  
- **Dataset Variability:** Performance sensitivity to SEM contrast differences  
- **Edge Cases:** Complex or mixed-defect regions  
- **Grayscale Limitations:** Subtle surface variations can be challenging  

</td>
</tr>
</table>

---

## âš¡ Edge Deployment Readiness

<div align="center">

### Why This Model is Edge-Ready

</div>

| Feature | Benefit | Impact |
|---------|---------|--------|
| ğŸ¯ **MobileNetV2** | Lightweight CNN architecture | Low compute requirements |
| ğŸ–¼ï¸ **Grayscale Input** | Single-channel processing | Reduced memory footprint |
| ğŸ“¦ **ONNX Format** | Cross-platform compatibility | Portable deployment |
| âš¡ **Efficient Inference** | Optimized depthwise convolutions | Fast predictions |
| ğŸ”§ **Transfer Learning** | Fewer parameters to train | Faster adaptation |

<div align="center">

### ğŸ® Target Platforms

[![NXP](https://img.shields.io/badge/NXP-eIQ-00A3E0?style=flat-square)](https://www.nxp.com)
[![NVIDIA](https://img.shields.io/badge/NVIDIA-Jetson-76B900?style=flat-square)](https://www.nvidia.com/jetson)
[![RPi](https://img.shields.io/badge/Raspberry-Pi-A22846?style=flat-square)](https://www.raspberrypi.org)
[![Intel](https://img.shields.io/badge/Intel-OpenVINO-0071C5?style=flat-square)](https://www.intel.com/openvino)

**Note:** This phase focuses on software-level validation. Hardware deployment and real-time benchmarking are planned for future phases.

</div>

